{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b66cea",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357d645",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = \n",
    "https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "A) Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5191bf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: requests in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.65.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cbf10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69139cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b10eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting version of chromedriver 115. Retrying with chromedriver 114 (attempt 1/5)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ac7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53305211",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817dedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]'):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')\n",
    "        \n",
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]'):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "        \n",
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('-')\n",
    "        \n",
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "        \n",
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]'):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e7560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Name),len(Artist),len(Date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e9fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"[42]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"[48]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[53]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    8.                          \"Wheels on the Bus\"[26]   \n",
       "7    7.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                                       \"Roar\"[39]   \n",
       "16  17.                             \"Counting Stars\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.                                      \"Sorry\"[42]   \n",
       "19  20.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "20  21.                          \"Thinking Out Loud\"[44]   \n",
       "21  22.                             \"Lakdi Ki Kathi\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.                                    \"Perfect\"[47]   \n",
       "24  25.                                      \"Faded\"[48]   \n",
       "25  26.                                 \"Let Her Go\"[49]   \n",
       "26  27.          \"Humpty the train on a fruits ride\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                   \"Bailando\"[52]   \n",
       "29  30.                                    \"Lean On\"[53]   \n",
       "\n",
       "                                    Artist               Date  Views  \n",
       "0   Pinkfong Baby Shark - children's songs      June 17, 2016  13.18  \n",
       "1                               Luis Fonsi   January 12, 2017   8.23  \n",
       "2             LooLoo Kids - nursery rhymes    October 8, 2016   6.76  \n",
       "3               Cocomelon - nursery rhymes        May 2, 2018   6.33  \n",
       "4                               Ed Sheeran   January 30, 2017   6.05  \n",
       "5                              Wiz Khalifa      April 6, 2015   5.98  \n",
       "6               Cocomelon - nursery rhymes       May 24, 2018   5.46  \n",
       "7             ChuChu TV - children's songs      March 6, 2014   5.42  \n",
       "8                              Mark Ronson  November 19, 2014   4.99  \n",
       "9           Miroshka TV - children's songs  February 27, 2018   4.94  \n",
       "10                                     Psy      July 15, 2012   4.86  \n",
       "11           Get Movies - children's songs   January 31, 2012   4.55  \n",
       "12                               El Chombo      April 5, 2018   4.41  \n",
       "13                              Crazy Frog      June 16, 2009   4.00  \n",
       "14                                Maroon 5   January 14, 2015   3.91  \n",
       "15                              Katy Perry  September 5, 2013   3.84  \n",
       "16                             OneRepublic       May 31, 2013   3.84  \n",
       "17              Cocomelon - nursery rhymes      June 25, 2018   3.73  \n",
       "18                           Justin Bieber   October 22, 2015   3.69  \n",
       "19                                 Shakira       June 4, 2010   3.68  \n",
       "20                              Ed Sheeran    October 7, 2014   3.63  \n",
       "21                            Jingle Toons      June 14, 2018   3.63  \n",
       "22                              Katy Perry  February 20, 2014   3.56  \n",
       "23                              Ed Sheeran   November 9, 2017   3.51  \n",
       "24                             Alan Walker   December 3, 2015   3.49  \n",
       "25                               Passenger      July 25, 2012   3.48  \n",
       "26      Kiddiestv Hindi - children's songs   January 26, 2018   3.51  \n",
       "27                                Maroon 5       May 31, 2018   3.45  \n",
       "28                        Enrique Iglesias     April 11, 2014   3.43  \n",
       "29                             Major Lazer     March 22, 2015   3.43  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Date':Date,'Views':Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d078c54",
   "metadata": {},
   "source": [
    "Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details: \n",
    "A) Match title (I.e. 1 ODI) \n",
    "B) Series \n",
    "C) Place \n",
    "D) Date \n",
    "E) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57bf0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8f1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "international=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e36798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f25bf556",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        Match_Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Match_Title.append('-')\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d231d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(Match_Title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "556a8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Gro...</td>\n",
       "      <td>13 AUG 2023</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village,</td>\n",
       "      <td>18 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village,</td>\n",
       "      <td>20 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village,</td>\n",
       "      <td>23 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                           Series  \\\n",
       "0  5th T20I -   INDIA TOUR OF WEST INDIES 2023   \n",
       "1  1st T20I -       INDIA TOUR OF IRELAND 2023   \n",
       "2  2nd T20I -       INDIA TOUR OF IRELAND 2023   \n",
       "3  3rd T20I -       INDIA TOUR OF IRELAND 2023   \n",
       "4   1st ODI -                    ASIA CUP 2023   \n",
       "5   2nd ODI -                    ASIA CUP 2023   \n",
       "6   1st ODI -  AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "7   2nd ODI -  AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                               Place         Date  \\\n",
       "0  Central Broward Regional Park Stadium Turf Gro...  13 AUG 2023   \n",
       "1                                       The Village,  18 AUG 2023   \n",
       "2                                       The Village,  20 AUG 2023   \n",
       "3                                       The Village,  23 AUG 2023   \n",
       "4           Pallekele International Cricket Stadium,   2 SEP 2023   \n",
       "5           Pallekele International Cricket Stadium,   4 SEP 2023   \n",
       "6      Punjab Cricket Association IS Bindra Stadium,  22 SEP 2023   \n",
       "7                            Holkar Cricket Stadium,  24 SEP 2023   \n",
       "\n",
       "           Time  \n",
       "0   8:00 PM IST  \n",
       "1   7:30 PM IST  \n",
       "2   7:30 PM IST  \n",
       "3   7:30 PM IST  \n",
       "4  10:00 AM IST  \n",
       "5  10:00 AM IST  \n",
       "6   1:30 PM IST  \n",
       "7   1:30 PM IST  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Match_Title':Match_Title,'Series':Series,'Place':Place,'Date':Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2872ece",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A)\n",
    "Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c284e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37357731",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/button').click()\n",
    "\n",
    "# clicking on India\n",
    "driver.find_element(By.XPATH,'//div[@class=\"dropdown-content\"]/a[3]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac57312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f91ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]'):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')\n",
    "    \n",
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]'):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('-')\n",
    "    \n",
    "# scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]'):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append('-')\n",
    "    \n",
    "# scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]'):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append('-')\n",
    "    \n",
    "# scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]'):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('-')\n",
    "    \n",
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]'):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06534d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP1</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State      GSDP1      GSDP2   Share GDP_billion\n",
       "0     1                Maharashtra          -  2,632,792  13.94%     399.921\n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%     247.629\n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%     240.726\n",
       "3     4                    Gujarat          -  1,502,899   7.96%     228.290\n",
       "4     5                  Karnataka  1,631,977  1,493,127   7.91%     226.806\n",
       "..  ...                        ...        ...        ...     ...         ...\n",
       "61   29                     Sikkim     28,391     25,141   0.15%      17,060\n",
       "62   30                   Nagaland          -     24,534   0.15%           -\n",
       "63   31          Arunachal Pradesh          -     22,488   0.13%           -\n",
       "64   32                    Mizoram     24,424     20,947   0.13%      17,797\n",
       "65   33  Andaman & Nicobar Islands          -          -       -           -\n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'State':State,'GSDP1':GSDP1,'GSDP2':GSDP2,'Share':Share,'GDP_billion':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b195a8b",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1056cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8b67925",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04c0a708",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1407690253.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 34\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in driver.find_elements(By.XPATH,'//ul[@class= \"list-style-none\"]//li//span[1]\"):\u001b[0m\n\u001b[1;37m                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]//a')\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute('href'))\n",
    "    \n",
    "# scraping Repository title data\n",
    "title = driver.find_elements(By.XPATH,'//h1[@class = \"h3 lh-condensed\"]')\n",
    "for i in title:\n",
    "    repository_title.append(i.text)\n",
    "    \n",
    "# scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # scraping Repository Description data \n",
    "    try:\n",
    "        desc = driver.find_elements(By.XPATH,'//p[@class=\"f4 mt-3\"]')\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    # scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_elements(By.XPATH,'//*[contains(text(),\"Contributors \")]')\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "    \n",
    "    \n",
    "    # scraping Languages used data\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//ul[@class= \"list-style-none\"]//li//span[1]\"):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "577d868c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Repository Title, Repository Description, Contributors Count, Language Used]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github = pd.DataFrame({})\n",
    "Github['Repository Title'] = repository_title\n",
    "Github['Repository Description'] = Description\n",
    "Github['Contributors Count'] = Contributors\n",
    "Github['Language Used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73636f75",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42fe9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "052cb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cf53e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_chart=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "view_chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e946439",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Artist = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58770402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last Night',\n",
       " 'Fast Car',\n",
       " 'Meltdown',\n",
       " 'Cruel Summer',\n",
       " 'FE!N',\n",
       " 'Calm Down',\n",
       " 'Fukumean',\n",
       " 'Barbie World',\n",
       " 'Vampire',\n",
       " 'Dance The Night',\n",
       " 'I Know ?',\n",
       " 'Flowers',\n",
       " 'All My Life',\n",
       " 'Hyaena',\n",
       " 'Snooze',\n",
       " 'Thank God',\n",
       " 'Topia Twins',\n",
       " 'K-POP',\n",
       " 'My Eyes',\n",
       " 'Karma',\n",
       " 'Try That In A Small Town',\n",
       " 'What Was I Made For?',\n",
       " 'Modern Jam',\n",
       " 'Need A Favor',\n",
       " 'Delresto (Echoes)',\n",
       " 'Telekinesis',\n",
       " 'Sirens',\n",
       " \"God's Country\",\n",
       " 'Kill Bill',\n",
       " 'Seven',\n",
       " 'Anti-Hero',\n",
       " \"Creepin'\",\n",
       " 'Religiously',\n",
       " 'Skitzo',\n",
       " 'Chemical',\n",
       " 'Circus Maximus',\n",
       " \"Thinkin' Bout Me\",\n",
       " 'Til Further Notice',\n",
       " 'Favorite Song',\n",
       " 'Mourning',\n",
       " 'Cupid',\n",
       " 'Ella Baila Sola',\n",
       " 'In Your Love',\n",
       " 'Dial Drunk',\n",
       " 'Next Thing You Know',\n",
       " 'Lost Forever',\n",
       " 'You, Me, & Whiskey',\n",
       " 'Love You Anyway',\n",
       " 'Looove',\n",
       " 'Thought You Should Know',\n",
       " 'Bury Me In Georgia',\n",
       " 'La Bebe',\n",
       " 'Parasail',\n",
       " 'Search & Rescue',\n",
       " 'Jealousy',\n",
       " 'Enough Is Enough',\n",
       " 'Put It On Da Floor Again',\n",
       " 'Deli',\n",
       " 'Un x100to',\n",
       " 'LaLa',\n",
       " 'Where She Goes',\n",
       " 'Princess Diana',\n",
       " 'Lady Gaga',\n",
       " \"Baby Don't Hurt Me\",\n",
       " 'Area Codes',\n",
       " 'What It Is (Block Boy)',\n",
       " 'Something Real',\n",
       " 'Overdrive',\n",
       " 'Peaches & Eggplants',\n",
       " 'Sabor Fresa',\n",
       " 'Watermelon Moonshine',\n",
       " 'Your Heart Or Mine',\n",
       " 'Eyes Closed',\n",
       " 'Daylight',\n",
       " 'Tulum',\n",
       " \"I Can See You (Taylor's Version) (From The Vault)\",\n",
       " 'Super Shy',\n",
       " 'Speed Drive',\n",
       " 'White Horse',\n",
       " 'On The Radar Freestyle',\n",
       " 'Stand By Me',\n",
       " 'Fragil',\n",
       " 'Everything I Love',\n",
       " 'Shake Sumn',\n",
       " 'TQM',\n",
       " 'Popular',\n",
       " 'Too Cool To Die',\n",
       " \"Don't Understand\",\n",
       " 'Aqui Te Espero',\n",
       " 'Novacandy',\n",
       " 'Truck Bed',\n",
       " \"I'm Just Ken\",\n",
       " 'Jaded',\n",
       " 'Heartbroken',\n",
       " 'Memory Lane',\n",
       " 'Oh U Went',\n",
       " 'ICU',\n",
       " 'Pound Town 2',\n",
       " 'Bzrp Music Sessions, Vol. 55',\n",
       " 'Johnny Dang']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//h3')\n",
    "    for i in names:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:       \n",
    "    Name.append('No details available')\n",
    "time.sleep(2)    \n",
    "Name[::4][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4077421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Morgan Wallen',\n",
       " 'Luke Combs',\n",
       " 'Travis Scott Featuring Drake',\n",
       " 'Taylor Swift',\n",
       " 'Travis Scott Featuring Playboi Carti',\n",
       " 'Rema & Selena Gomez',\n",
       " 'Gunna',\n",
       " 'Nicki Minaj & Ice Spice With Aqua',\n",
       " 'Olivia Rodrigo',\n",
       " 'Dua Lipa',\n",
       " 'Travis Scott',\n",
       " 'Miley Cyrus',\n",
       " 'Lil Durk Featuring J. Cole',\n",
       " 'Travis Scott',\n",
       " 'SZA',\n",
       " 'Travis Scott',\n",
       " 'Travis Scott Featuring Rob49 & 21 Savage',\n",
       " 'Travis Scott, Bad Bunny & The Weeknd',\n",
       " 'Travis Scott',\n",
       " 'Taylor Swift Featuring Ice Spice',\n",
       " 'Jason Aldean',\n",
       " 'Billie Eilish',\n",
       " 'Travis Scott Featuring Teezo Touchdown',\n",
       " 'Jelly Roll',\n",
       " 'Travis Scott & Beyonce',\n",
       " 'Travis Scott Featuring SZA & Future',\n",
       " 'Travis Scott',\n",
       " 'Travis Scott',\n",
       " 'SZA',\n",
       " 'Jung Kook Featuring Latto',\n",
       " 'Taylor Swift',\n",
       " 'Metro Boomin, The Weeknd & 21 Savage',\n",
       " 'Bailey Zimmerman',\n",
       " 'Travis Scott Featuring Young Thug',\n",
       " 'Post Malone',\n",
       " 'Travis Scott Featuring The Weeknd & Swae Lee',\n",
       " 'Morgan Wallen',\n",
       " 'Travis Scott Featuring James Blake & 21 Savage',\n",
       " 'Toosii',\n",
       " 'Post Malone',\n",
       " 'Fifty Fifty',\n",
       " 'Eslabon Armado X Peso Pluma',\n",
       " 'Tyler Childers',\n",
       " 'Noah Kahan With Post Malone',\n",
       " 'Jordan Davis',\n",
       " 'Travis Scott Featuring Westside Gunn',\n",
       " 'Justin Moore & Priscilla Block',\n",
       " 'Luke Combs',\n",
       " 'Travis Scott Featuring Kid Cudi',\n",
       " 'Morgan Wallen',\n",
       " 'Kane Brown',\n",
       " 'Yng Lvcas x Peso Pluma',\n",
       " 'Travis Scott Featuring Yung Lean & Dave Chappelle',\n",
       " 'Drake',\n",
       " 'Offset & Cardi B',\n",
       " 'Post Malone',\n",
       " 'Latto Featuring Cardi B',\n",
       " 'Ice Spice',\n",
       " 'Grupo Frontera X Bad Bunny',\n",
       " 'Myke Towers',\n",
       " 'Bad Bunny',\n",
       " 'Ice Spice & Nicki Minaj',\n",
       " 'Peso Pluma, Gabito Ballesteros & Junior H',\n",
       " 'David Guetta, Anne-Marie & Coi Leray',\n",
       " 'Kaliii',\n",
       " 'Doechii Featuring Kodak Black',\n",
       " 'Post Malone',\n",
       " 'Post Malone',\n",
       " 'Young Nudy Featuring 21 Savage',\n",
       " 'Fuerza Regida',\n",
       " 'Lainey Wilson',\n",
       " 'Jon Pardi',\n",
       " 'Ed Sheeran',\n",
       " 'David Kushner',\n",
       " 'Peso Pluma & Grupo Frontera',\n",
       " 'Taylor Swift',\n",
       " 'NewJeans',\n",
       " 'Charli XCX',\n",
       " 'Chris Stapleton',\n",
       " 'Drake & Central Cee',\n",
       " 'Lil Durk Featuring Morgan Wallen',\n",
       " 'Yahritza y Su Esencia x Grupo Frontera',\n",
       " 'Morgan Wallen',\n",
       " 'DaBaby',\n",
       " 'Fuerza Regida',\n",
       " 'The Weeknd, Playboi Carti & Madonna',\n",
       " 'Post Malone',\n",
       " 'Post Malone',\n",
       " 'Ivan Cornejo',\n",
       " 'Post Malone',\n",
       " 'HARDY',\n",
       " 'Ryan Gosling',\n",
       " 'Miley Cyrus',\n",
       " 'Diplo, Jessie Murph & Polo G',\n",
       " 'Old Dominion',\n",
       " 'Young Thug Featuring Drake',\n",
       " 'Coco Jones',\n",
       " 'Sexyy Red & Tay Keith & Nicki Minaj',\n",
       " 'Bizarrap & Peso Pluma',\n",
       " 'That Mexican OT, Paul Wall & DRODi']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//span')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:     \n",
    "    Artist.append('-')\n",
    "time.sleep(2)    \n",
    "Artist[::7][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e44e84e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '3',\n",
       " '-',\n",
       " '6',\n",
       " '-',\n",
       " '5',\n",
       " '4',\n",
       " '8',\n",
       " '10',\n",
       " '12',\n",
       " '-',\n",
       " '11',\n",
       " '13',\n",
       " '-',\n",
       " '14',\n",
       " '-',\n",
       " '-',\n",
       " '7',\n",
       " '-',\n",
       " '15',\n",
       " '1',\n",
       " '18',\n",
       " '-',\n",
       " '16',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '17',\n",
       " '9',\n",
       " '22',\n",
       " '20',\n",
       " '24',\n",
       " '-',\n",
       " '46',\n",
       " '-',\n",
       " '27',\n",
       " '-',\n",
       " '23',\n",
       " '60',\n",
       " '29',\n",
       " '28',\n",
       " '-',\n",
       " '25',\n",
       " '30',\n",
       " '-',\n",
       " '52',\n",
       " '37',\n",
       " '-',\n",
       " '34',\n",
       " '39',\n",
       " '32',\n",
       " '-',\n",
       " '35',\n",
       " '-',\n",
       " '-',\n",
       " '42',\n",
       " '41',\n",
       " '36',\n",
       " '49',\n",
       " '43',\n",
       " '40',\n",
       " '51',\n",
       " '55',\n",
       " '53',\n",
       " '58',\n",
       " '-',\n",
       " '-',\n",
       " '57',\n",
       " '50',\n",
       " '61',\n",
       " '54',\n",
       " '44',\n",
       " '59',\n",
       " '56',\n",
       " '45',\n",
       " '48',\n",
       " '73',\n",
       " '31',\n",
       " '-',\n",
       " '62',\n",
       " '70',\n",
       " '67',\n",
       " '65',\n",
       " '63',\n",
       " '68',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '69',\n",
       " '87',\n",
       " '78',\n",
       " '64',\n",
       " '47',\n",
       " '66',\n",
       " '71',\n",
       " '74',\n",
       " '72',\n",
       " '96']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping last week rank of the song\n",
    "try:\n",
    "    last_rank=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]')\n",
    "    for i in last_rank:\n",
    "        Last_week_rank.append(i.text)\n",
    "except NoSuchElementException:      \n",
    "    Last_week_rank.append('-')\n",
    "    time.sleep(2)    \n",
    "Last_week_rank[::2][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34804c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '3',\n",
       " '4',\n",
       " '7',\n",
       " '1',\n",
       " '10',\n",
       " '11',\n",
       " '1',\n",
       " '2',\n",
       " '14',\n",
       " '11',\n",
       " '16',\n",
       " '17',\n",
       " '7',\n",
       " '19',\n",
       " '2',\n",
       " '1',\n",
       " '18',\n",
       " '23',\n",
       " '14',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '24',\n",
       " '34',\n",
       " '13',\n",
       " '36',\n",
       " '9',\n",
       " '38',\n",
       " '5',\n",
       " '36',\n",
       " '17',\n",
       " '4',\n",
       " '43',\n",
       " '25',\n",
       " '23',\n",
       " '46',\n",
       " '47',\n",
       " '15',\n",
       " '49',\n",
       " '7',\n",
       " '39',\n",
       " '11',\n",
       " '53',\n",
       " '2',\n",
       " '55',\n",
       " '56',\n",
       " '13',\n",
       " '41',\n",
       " '5',\n",
       " '48',\n",
       " '8',\n",
       " '4',\n",
       " '35',\n",
       " '55',\n",
       " '33',\n",
       " '54',\n",
       " '67',\n",
       " '47',\n",
       " '52',\n",
       " '26',\n",
       " '60',\n",
       " '53',\n",
       " '19',\n",
       " '47',\n",
       " '43',\n",
       " '5',\n",
       " '48',\n",
       " '73',\n",
       " '31',\n",
       " '80',\n",
       " '22',\n",
       " '69',\n",
       " '14',\n",
       " '65',\n",
       " '34',\n",
       " '43',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '69',\n",
       " '87',\n",
       " '56',\n",
       " '64',\n",
       " '27',\n",
       " '19',\n",
       " '62',\n",
       " '66',\n",
       " '31',\n",
       " '96']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping song's peak rank\n",
    "try:\n",
    "    peak=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]')\n",
    "    for i in peak:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:       \n",
    "    Peak_rank.append('-')\n",
    "time.sleep(2)    \n",
    "Peak_rank[1::2][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf595977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27',\n",
       " '19',\n",
       " '1',\n",
       " '13',\n",
       " '1',\n",
       " '48',\n",
       " '7',\n",
       " '6',\n",
       " '5',\n",
       " '10',\n",
       " '1',\n",
       " '29',\n",
       " '12',\n",
       " '1',\n",
       " '34',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '21',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '18',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '34',\n",
       " '3',\n",
       " '41',\n",
       " '35',\n",
       " '13',\n",
       " '1',\n",
       " '16',\n",
       " '1',\n",
       " '22',\n",
       " '1',\n",
       " '24',\n",
       " '11',\n",
       " '20',\n",
       " '20',\n",
       " '1',\n",
       " '7',\n",
       " '28',\n",
       " '1',\n",
       " '13',\n",
       " '25',\n",
       " '1',\n",
       " '51',\n",
       " '12',\n",
       " '20',\n",
       " '1',\n",
       " '17',\n",
       " '1',\n",
       " '1',\n",
       " '9',\n",
       " '2',\n",
       " '16',\n",
       " '4',\n",
       " '11',\n",
       " '16',\n",
       " '6',\n",
       " '11',\n",
       " '13',\n",
       " '13',\n",
       " '1',\n",
       " '2',\n",
       " '9',\n",
       " '6',\n",
       " '6',\n",
       " '12',\n",
       " '19',\n",
       " '16',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '2',\n",
       " '2',\n",
       " '1',\n",
       " '10',\n",
       " '15',\n",
       " '23',\n",
       " '11',\n",
       " '11',\n",
       " '9',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '2',\n",
       " '11',\n",
       " '2',\n",
       " '18',\n",
       " '6',\n",
       " '18',\n",
       " '9',\n",
       " '9',\n",
       " '3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping number of weeks on board\n",
    "try:\n",
    "    weeks=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]')\n",
    "    for i in weeks:\n",
    "        Weeks_on_board.append(i.text)\n",
    "except NoSuchElementException:       #handling no such element exception\n",
    "    Weeks_on_board.append('-')\n",
    "time.sleep(2)    \n",
    "Weeks_on_board[1::2][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fca2783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meltdown</td>\n",
       "      <td>Travis Scott Featuring Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FE!N</td>\n",
       "      <td>Travis Scott Featuring Playboi Carti</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Oh U Went</td>\n",
       "      <td>Young Thug Featuring Drake</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ICU</td>\n",
       "      <td>Coco Jones</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pound Town 2</td>\n",
       "      <td>Sexyy Red &amp; Tay Keith &amp; Nicki Minaj</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Johnny Dang</td>\n",
       "      <td>That Mexican OT, Paul Wall &amp; DRODi</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song_Name                           Artist_Name  \\\n",
       "0                     Last Night                         Morgan Wallen   \n",
       "1                       Fast Car                            Luke Combs   \n",
       "2                       Meltdown          Travis Scott Featuring Drake   \n",
       "3                   Cruel Summer                          Taylor Swift   \n",
       "4                           FE!N  Travis Scott Featuring Playboi Carti   \n",
       "..                           ...                                   ...   \n",
       "95                     Oh U Went            Young Thug Featuring Drake   \n",
       "96                           ICU                            Coco Jones   \n",
       "97                  Pound Town 2   Sexyy Red & Tay Keith & Nicki Minaj   \n",
       "98  Bzrp Music Sessions, Vol. 55                 Bizarrap & Peso Pluma   \n",
       "99                   Johnny Dang    That Mexican OT, Paul Wall & DRODi   \n",
       "\n",
       "   Last_week_rank Peak Weeks_on_chart  \n",
       "0               2    1             27  \n",
       "1               3    2             19  \n",
       "2               -    3              1  \n",
       "3               6    4             13  \n",
       "4               -    5              1  \n",
       "..            ...  ...            ...  \n",
       "95             66   19              6  \n",
       "96             71   62             18  \n",
       "97             74   66              9  \n",
       "98             72   31              9  \n",
       "99             96   96              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Song_Name':Name[::4][:100],\n",
    "                'Artist_Name':Artist[::7][:100],\n",
    "                'Last_week_rank':Last_week_rank[::2][:100],\n",
    "                'Peak':Peak_rank[1::2][:100],\n",
    "                'Weeks_on_chart':Weeks_on_board[1::2][:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974aff2",
   "metadata": {},
   "source": [
    "6 Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002You have to find the following details\n",
    "  . Scrape the details of Highest selling novels. \n",
    "compare \n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cfc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.theguardian.com/world/2002/may/08/books.booksnews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed8b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfb9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,'//tbody//tr//td[2]'):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "# scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,'//tbody//tr//td[3]'):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,'//tbody//tr//td[4]'):\n",
    "    Volumes_sold.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,'//tbody//tr//td[5]'):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraping  data of genre\n",
    "for i in driver.find_elements(By.XPATH,'//tbody//tr//td[6]'):\n",
    "    Genre.append(i.text)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ef92a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Volume sold, Publisher, Genre]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01431e16",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You \n",
    "have to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b4afb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4bb0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e120923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd5d6bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,192,114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,266,025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>210,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,192,114  \n",
       "1    51 min     8.7  1,266,025  \n",
       "2    44 min     8.1  1,040,572  \n",
       "3    60 min     7.5    305,843  \n",
       "4    43 min     7.6    264,919  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,406  \n",
       "96   50 min     7.8     64,430  \n",
       "97   42 min     8.1    210,000  \n",
       "98   45 min       7     43,661  \n",
       "99  572 min     8.6    263,461  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB=pd.DataFrame({})\n",
    "IMDB['Name'] = Name\n",
    "IMDB['Year Span'] = Year_span\n",
    "IMDB['Genre'] = Genre\n",
    "IMDB['Run Time'] = Run_time\n",
    "IMDB['Ratings'] = Ratings\n",
    "IMDB['Votes'] = Votes\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e82585",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute G) Year \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc026236",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4b2d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = driver.find_elements(By.XPATH,'//p[@class=\"normal\"]//b/a')\n",
    "\n",
    "urls = []\n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "707c18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebf2c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping  Dataset name\n",
    "    try:\n",
    "        dataset_name = driver.find_elements(By.XPATH,'//span[@class=\"heading\"]')\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_elements(By.XPATH,'//table[@border=\"1\"]//tbody/tr/td[2]')\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping Task\n",
    "    try:\n",
    "        task = driver.find_elements(By.XPATH,'//table[@border=\"1\"]//tbody/tr[3]/td[2]')\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_elements(By.XPATH,'//table[@border=\"1\"]//tbody/tr[2]/td[2]')\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping No of Instances\n",
    "    try:\n",
    "        instances = driver.find_elements(By.XPATH,'//table[@border=\"1\"]//tbody/tr/td[4]')\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping No of Arrtibutes\n",
    "    try:\n",
    "        attribute = driver.find_elements(By.XPATH,'//table[@border=\"1\"]//tbody/tr[2]/td[4]')\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping Year\n",
    "    try:\n",
    "        year = driver.find_elements(By.XPATH,'//table[@border=\"1\"]//tbody/tr[2]/td[6]')\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bcb7d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instance</th>\n",
       "      <th>No_of_attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Dataset_name, Data_type, Task, Attribute_type, No_of_instance, No_of_attributes, Year]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML = pd.DataFrame({})\n",
    "ML['Dataset_name'] = Dataset_name\n",
    "ML['Data_type'] = Data_type\n",
    "ML['Task'] = Task \n",
    "ML['Attribute_type'] = Attribute_type \n",
    "ML['No_of_instance'] = No_of_instances\n",
    "ML['No_of_attributes'] = No_of_attributes \n",
    "ML['Year'] = Year \n",
    "ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f4500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
