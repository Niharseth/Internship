{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070b753b",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f602b92",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0da39ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: requests in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.65.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b45d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\cape-mumbai\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f485f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c383c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.30M/6.30M [00:05<00:00, 1.31MB/s]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93afcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e807579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bfca8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "652abee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e45fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed4ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b56b3997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "090b40fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Persolkelly India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Everest Vacuum</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Shell</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA ANALYST III</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune</td>\n",
       "      <td>Synchron Infotech</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yulu Bikes</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Paychex It Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka(Hebbal Kempapura)</td>\n",
       "      <td>Futurlytic</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EDI - DATA ANALYST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Atos</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Title                                           Location  \\\n",
       "0        Data Analyst  Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...   \n",
       "1        Data Analyst                                Bangalore/Bengaluru   \n",
       "2        Data Analyst                                Bangalore/Bengaluru   \n",
       "3        Data Analyst                       Bangalore/Bengaluru, Chennai   \n",
       "4    DATA ANALYST III                                Bangalore/Bengaluru   \n",
       "5        Data Analyst  Bangalore/Bengaluru, Hyderabad/Secunderabad, Pune   \n",
       "6        Data Analyst                                Bangalore/Bengaluru   \n",
       "7        Data Analyst                                Bangalore/Bengaluru   \n",
       "8        Data Analyst  Bangalore/ Bengaluru, Karnataka(Hebbal Kempapura)   \n",
       "9  EDI - DATA ANALYST                                Bangalore/Bengaluru   \n",
       "\n",
       "           company_name Experience  \n",
       "0             Delhivery    1-3 Yrs  \n",
       "1     Persolkelly India    0-2 Yrs  \n",
       "2        Everest Vacuum    2-5 Yrs  \n",
       "3                 Shell    1-2 Yrs  \n",
       "4               Walmart    7-9 Yrs  \n",
       "5     Synchron Infotech    5-8 Yrs  \n",
       "6            Yulu Bikes    4-6 Yrs  \n",
       "7  Paychex It Solutions    3-8 Yrs  \n",
       "8            Futurlytic    1-2 Yrs  \n",
       "9                  Atos    3-5 Yrs  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d60a9",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b10563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bfdf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b4a2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf500220",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "890a3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "069d3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aee778a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09a838cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr . Data Scientist / Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Novitas Infotech</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Novitas Infotech</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist with Retail Domain</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Nagpur, ...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai, Hyderabad/...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0            Data Science Specialist   \n",
       "1   Analystics & Modeling Specialist   \n",
       "2      Sr . Data Scientist / Manager   \n",
       "3                     Data Scientist   \n",
       "4  Data Scientist with Retail Domain   \n",
       "5                     Data Scientist   \n",
       "6                     Data Scientist   \n",
       "7                     Data Scientist   \n",
       "8                     Data Scientist   \n",
       "9                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2       Bangalore/Bengaluru, Noida, Gurgaon/Gurugram   \n",
       "3       Bangalore/Bengaluru, Noida, Gurgaon/Gurugram   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, Nagpur, ...   \n",
       "5  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...   \n",
       "6  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...   \n",
       "7  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...   \n",
       "8  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...   \n",
       "9  Bangalore/Bengaluru, Noida, Mumbai, Hyderabad/...   \n",
       "\n",
       "               company_name Experience  \n",
       "0                 Accenture    2-4 Yrs  \n",
       "1                 Accenture    6-8 Yrs  \n",
       "2          Novitas Infotech   7-10 Yrs  \n",
       "3          Novitas Infotech    3-7 Yrs  \n",
       "4  TRH Consultancy Services    4-9 Yrs  \n",
       "5  TRH Consultancy Services   5-10 Yrs  \n",
       "6  TRH Consultancy Services   5-10 Yrs  \n",
       "7  TRH Consultancy Services   5-10 Yrs  \n",
       "8  TRH Consultancy Services   5-10 Yrs  \n",
       "9  TRH Consultancy Services   5-10 Yrs  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58ec5b",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respectiveboxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scrapeddata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "964fe5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad15f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "576b75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d79f6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=[]\n",
    "salary_filter=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a642779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft filterLabel\"]')\n",
    "for i in loc_filter:\n",
    "    if(i.text=='Delhi / NCR'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "462a6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft filterLabel\"]')\n",
    "for i in salary_filter:\n",
    "    if(i.text=='3-6 Lakhs'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "926b7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68002deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ca487ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32dabdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist/ Manager...</td>\n",
       "      <td>Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...</td>\n",
       "      <td>Dreambig It Solutions India</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intern</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Tower Research Capital</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Benovymed Healthcare</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                              Junior Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2  Data Scientist/ Senior Data Scientist/ Manager...   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                              Python and ML Trainer   \n",
       "6                                             Intern   \n",
       "7                          Hiring For Data Scientist   \n",
       "8                              Junior Data Scientist   \n",
       "9                           Principal Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2  Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4                                              Noida   \n",
       "5  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                             Remote   \n",
       "8    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                  company_name Experience  \n",
       "0                     Analytos    0-2 Yrs  \n",
       "1                    Blackbuck    3-7 Yrs  \n",
       "2  Dreambig It Solutions India    1-6 Yrs  \n",
       "3                     Analytos    2-4 Yrs  \n",
       "4               Times Internet    3-8 Yrs  \n",
       "5                   Thescholar    3-8 Yrs  \n",
       "6       Tower Research Capital    0-1 Yrs  \n",
       "7                     Infogain    4-9 Yrs  \n",
       "8                       Adidas    1-6 Yrs  \n",
       "9         Benovymed Healthcare    2-7 Yrs  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a832f",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data asusual\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349edd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31bdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_field.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ea6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8eae200",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product_Descrption=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb38396",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:40]:\n",
    "    brand=i.text\n",
    "    Brand.append(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bd190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in product_tags[0:40]:\n",
    "    product=i.text\n",
    "    Product_Descrption.append(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36db1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:40]:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "082a5d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 36 40\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Descrption),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5276cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(brand)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8184918",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):\n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in brand:\n",
    "        Product_Descrption.append(product)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f75ffbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in brand:\n",
    "        Price.append(price)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8bf543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 127 131\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Descrption),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee9d9616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Descrption</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (48)</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Riding Glasses, Night Vision Wayfarer Sunglass...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                 Product_Descrption Price\n",
       "0    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (48)  ₹648\n",
       "1    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹648\n",
       "2    VINCENT CHASE  UV Protection Cat-eye, Retro Square, Oval, Rou...  ₹648\n",
       "3    VINCENT CHASE             UV Protection Wayfarer Sunglasses (50)  ₹648\n",
       "4    VINCENT CHASE  Riding Glasses, Night Vision Wayfarer Sunglass...  ₹648\n",
       "..             ...                                                ...   ...\n",
       "122  VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹648\n",
       "123  VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹648\n",
       "124  VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹648\n",
       "125  VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹648\n",
       "126  VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹648\n",
       "\n",
       "[127 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand,'Product_Descrption':Product_Descrption,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0959b81",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cccec921",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d1ac48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6974a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    Rating.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2af07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    review=i.text\n",
    "    Review_summary.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67fcb317",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    full=i.text\n",
    "    Full_review.append(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d49652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=11\n",
    "for page in range(start,end):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating:\n",
    "        Rating.append(rating)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b892f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=11\n",
    "for page in range(start,end):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review:\n",
    "        Review_summary.append(review)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5462ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=11\n",
    "for page in range(start,end):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in review:\n",
    "        Full_review.append(full)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69adb867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 21 21\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee062720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating Review_summary Full_review\n",
       "0       5              5           5\n",
       "1       5              5           5\n",
       "2       5              5           5\n",
       "3       5              5           5\n",
       "4       5              5           5\n",
       "5       5              5           5\n",
       "6       5              5           5\n",
       "7       5              5           5\n",
       "8       5              5           5\n",
       "9       5              5           5\n",
       "10      5              5           5\n",
       "11      5              5           5\n",
       "12      5              5           5\n",
       "13      5              5           5\n",
       "14      5              5           5\n",
       "15      5              5           5\n",
       "16      5              5           5\n",
       "17      5              5           5\n",
       "18      5              5           5\n",
       "19      5              5           5\n",
       "20      5              5           5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rating':rating,'Review_summary':Review_summary,'Full_review':full})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22251296",
   "metadata": {},
   "source": [
    "Q6: Scrape data forfirst 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "653352ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc5f05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_field.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5424077",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58518536",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product_Descrption=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efbd88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:40]:\n",
    "    brand=i.text\n",
    "    Brand.append(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75daeb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in product_tags[0:40]:\n",
    "    product=i.text\n",
    "    Product_Descrption.append(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaa180e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:40]:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b98fd590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 38 40\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Descrption),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b247a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=6\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(brand)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6dfc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=6\n",
    "for page in range(start,end):\n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in brand:\n",
    "        Product_Descrption.append(product)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "136df8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=6\n",
    "for page in range(start,end):\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in brand:\n",
    "        Price.append(price)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a65ca525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 113 115\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Descrption),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "561b4d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Descrption</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium White Sneakers For women Sneakers For ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium White Sneakers For women Sneakers For ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium White Sneakers For women Sneakers For ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium White Sneakers For women Sneakers For ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium White Sneakers For women Sneakers For ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand                                 Product_Descrption Price\n",
       "0    BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men  ₹399\n",
       "1    BIRDE  Stylish & Trending Outdoor Walking Comfortable...  ₹399\n",
       "2    BIRDE  Synthetic Leather |Lightweight|Comfort|Summer|...  ₹399\n",
       "3    BIRDE                                   Sneakers For Men  ₹399\n",
       "4    BIRDE                                 Sneakers For Women  ₹399\n",
       "..     ...                                                ...   ...\n",
       "108  BIRDE  Premium White Sneakers For women Sneakers For ...  ₹399\n",
       "109  BIRDE  Premium White Sneakers For women Sneakers For ...  ₹399\n",
       "110  BIRDE  Premium White Sneakers For women Sneakers For ...  ₹399\n",
       "111  BIRDE  Premium White Sneakers For women Sneakers For ...  ₹399\n",
       "112  BIRDE  Premium White Sneakers For women Sneakers For ...  ₹399\n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand,'Product_Descrption':Product_Descrption,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5110dbf5",
   "metadata": {},
   "source": [
    "Q7. Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb67b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0cad7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_col=driver.find_element(By.XPATH,'//input[@class=\"nav-input nav-progressive-attribute\"]')\n",
    "search_col.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29cb1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d361f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_filter=driver.find_elements(By.XPATH,'//span[@class=\"a-size-base a-color-base\"]')\n",
    "for i in type_filter:\n",
    "    if(i.text=='Intel Core i7'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "872f2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67765056",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "    \n",
    "ratings_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-icon-alt\"]/..')\n",
    "for i in ratings_tags[0:10]:\n",
    "    ratings=i.text\n",
    "    Ratings.append(ratings)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c5a3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cabf0a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td></td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Creator Series Vivobook 14X OLED (2023), ...</td>\n",
       "      <td></td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer Nitro 5 AN515-58 Gaming Laptop 12th Gen I...</td>\n",
       "      <td></td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>86,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell Vostro 5630 13th Gen Laptop, Intel Core i...</td>\n",
       "      <td></td>\n",
       "      <td>90,004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>71,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell 7480 Intel Core i7 14-Inch (35....</td>\n",
       "      <td></td>\n",
       "      <td>25,994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) HP Laptop 15s, 12th Gen Intel Core i...</td>\n",
       "      <td></td>\n",
       "      <td>66,663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...            62,990\n",
       "1  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...            64,990\n",
       "2  ASUS Creator Series Vivobook 14X OLED (2023), ...            92,990\n",
       "3  Acer Nitro 5 AN515-58 Gaming Laptop 12th Gen I...          1,04,990\n",
       "4  Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...            86,390\n",
       "5  Dell Vostro 5630 13th Gen Laptop, Intel Core i...            90,004\n",
       "6  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...            71,490\n",
       "7  (Renewed) Dell 7480 Intel Core i7 14-Inch (35....            25,994\n",
       "8  HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...            79,990\n",
       "9  (Renewed) HP Laptop 15s, 12th Gen Intel Core i...            66,663"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':Title,'Ratings':Ratings,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c17106",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cffa5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf3edcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quotes=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0e3cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote=[]\n",
    "Author=[]\n",
    "Type_of_quotes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ae2cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in quote_tags[0:100]:\n",
    "    quote=i.text\n",
    "    Quote.append(quote)\n",
    "    \n",
    "author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author=i.text\n",
    "    Author.append(author)\n",
    "    \n",
    "type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in type_tags[0:100]:\n",
    "    type=i.text\n",
    "    Type_of_quotes.append(type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75c75a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote),len(Author),len(Type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6749e185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type_of_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quote                Author  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                              Type_of_quotes  \n",
       "0   Essence, Deep Thought, Transcendentalism  \n",
       "1                  Inspiration, Past, Trying  \n",
       "2                        Country, Peace, War  \n",
       "3         Inspirational, Motivational, Death  \n",
       "4               4th Of July, Food, Patriotic  \n",
       "..                                       ...  \n",
       "95                    Music, Sports, Hunting  \n",
       "96             Trust, Encouraging, Uplifting  \n",
       "97              Inspirational, Funny, Change  \n",
       "98                      Success, God, Mother  \n",
       "99       Inspirational, Motivational, Change  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Quote':Quote,'Author':Author,'Type_of_quotes':Type_of_quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76f469",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58fc7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8691f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gk=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bc0ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_minister=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "prime_minister.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5020e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_name=[]\n",
    "Born_Dead=[]\n",
    "Term_of_office=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e84c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[2]/p/strong/a')\n",
    "for i in pm_tags[0:10]:\n",
    "    pm=i.text\n",
    "    pm_name.append(pm)\n",
    "\n",
    "bd_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[3]/p')\n",
    "for i in bd_tags[0:10]:\n",
    "    bd=i.text\n",
    "    Born_Dead.append(bd)\n",
    "\n",
    "term_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[4]/p[1]/span')\n",
    "for i in term_tags[0:10]:\n",
    "    term=i.text\n",
    "    Term_of_office.append(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac915c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_name</th>\n",
       "      <th>Born_Dead</th>\n",
       "      <th>Term_of_office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pm_name, Born_Dead, Term_of_office]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'pm_name':pm_name,'Born_Dead':Born_Dead,'Term_of_office':Term_of_office})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304d363",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c3ca56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10db7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field=driver.find_element(By.XPATH,'//input[@class=\"m1-search-panel-input m1-search-form-text\"]')\n",
    "search_field.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ca41bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//button[@class=\"m1-search-panel-button m1-search-form-button-animate icon-search-svg\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63899ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive=driver.find_elements(By.XPATH,'/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a')\n",
    "expensive.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "920cb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35118ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_tags=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in cars_tags[0:10]:\n",
    "    cars=i.text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01c69615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "795b1695",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcars\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcars\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:656\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m have_series:\n\u001b[0;32m    659\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'cars':cars})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe8c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
